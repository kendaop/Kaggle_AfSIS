as.integer(wind)
probs["head"] / probs["tail"]
probs["tail"] / probs["head"]
source('~/R/TEST.R')
modfit$coefficients
exp(modfit$coefficients)
source('~/R/TEST.R')
source('~/R/TEST.R')
magn
source('~/R/TEST.R')
exp(modfit$coefficients[2])
source('~/R/TEST.R')
exp(modfit$coefficients[2])
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
use
as.integer(use)
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
InsectSprays
data=InsectSprays
names(data)
source('~/R/TEST.R')
exp(.05588)
1.057471*2.67415
2.827836-2.67415
source('~/R/TEST.R')
exp(.05588)
exp(-.05588)
as.factor(spray)
as.integer(spray)
as.factor(as.integer(spray))
source('~/R/TEST.R')
log(10)
as.factor(as.integer(spray)) + log(10)
as.factor(as.integer(spray) + log(10))
as.integer(spray) + log(10)
source('~/R/TEST.R')
source('~/R/TEST.R')
x
y
plot(y ~ x)
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
y[y <= 0]
y
x[x <= 0]
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
lm1
ls(lm1)
summary(lm1)
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
summary(lm1)
ls(lm1)
lm1$model
lm1$call
lm1$assign
abline(lm(I(y + lm1$coefficients[1]) ~ x, subset=x[x <= 0]))
abline(lm(I(y - lm1$coefficients[1]) ~ x, subset=x[x <= 0]))
source('~/R/TEST.R')
abline(v=0)
abline(h=0)
lm1$fitted.values
lm1$model
source('~/R/TEST.R')
lm2$fitted.values
lm2
abline(lm2)
lm2
ls(lm2)
lm2$model
lm1$model
lm1$fitted.values
lm2$fitted.values
source('~/R/TEST.R')
yhat
yhat[3] / 5
1.013*5
source('~/R/TEST.R')
source('~/R/TEST.R')
vowel.test
vowel.train
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
table(gbmpredict, vowel.test$y)
summary(gbmpredict)
vowel.test[vowel.test$y != gbmpredict, "y"]
vowel.test$y
length(vowel.test[vowel.test$y != gbmpredict, "y"])
length(vowel.test[vowel.test$y == gbmpredict, "y"])
237/(237+225)
length(vowel.test[vowel.test$y == rfpredict, "y"])
length(vowel.test[vowel.test$y != rfpredict, "y"])
281/(281+181)
length(vowel.test[vowel.test$y == rfpredict == gbmpredict, "y"])
length(vowel.test[vowel.test$y == rfpredict & rfpredict == gbmpredict, "y"])
length(vowel.test[vowel.test$y != rfpredict & rfpredict == gbmpredict, "y"])
205/(205+112)
source('~/R/TEST.R')
rm(vowel.train)
rm(vowel.test)
gc()
source('~/R/TEST.R')
trainControl()
source('~/R/TEST.R')
predictions = data.frame(predrf, predgbm, predlda, testing$diagnosis)
sum((predictions[,1] == predictions[,4]) ^ 2)
sum((predictions[,2] == predictions[,4]) ^ 2)
sum((predictions[,3] == predictions[,4]) ^ 2)
predictions[,3] == predictions[,4]
(predictions[,3] == predictions[,4]) * 1
((predictions[,3] == predictions[,4]) * 1) / nrow(predictions)
(predictions[,3] == predictions[,4]) * 1
sum((predictions[,3] == predictions[,4]) * 1)
sum((predictions[,3] == predictions[,4]) * 1) / nrow(predictions)
sum((predictions[,1] == predictions[,4]) * 1) / nrow(predictions)
sum((predictions[,2] == predictions[,4]) * 1) / nrow(predictions)
sum((predictions[,3] == predictions[,4]) * 1) / nrow(predictions)
sum(predictions[,1] == predictions[,4])
accuracies = with(predictions, c(rf=accuracy(predrf), gbm=accuracy(predgbm), lda=accuracy(predlda)))
accuracy = function(x) {
sum(x == predictions[,4]) / nrow(predictions)
}
accuracies = with(predictions, c(rf=accuracy(predrf), gbm=accuracy(predgbm), lda=accuracy(predlda)))
accuracies
# Create stacked model using Random Forests
message("Training model...")
begin = Sys.time()
stackedmod = train(predictions[,4] ~ ., method="rf")
end = Sys.time()
message(sprintf("Time to fit model, with %d cores: %d minutes %d seconds.",
detectCores() - ignorecores,
floor(as.numeric(end-begin, units="mins")),
floor(as.numeric(end-begin, units="secs")) %% 60))
# Create stacked model using Random Forests
message("Training model...")
begin = Sys.time()
stackedmod = train(predictions[,4] ~ ., data=predictions, method="rf")
end = Sys.time()
message(sprintf("Time to fit model, with %d cores: %d minutes %d seconds.",
detectCores() - ignorecores,
floor(as.numeric(end-begin, units="mins")),
floor(as.numeric(end-begin, units="secs")) %% 60))
# Calculate accuracies of predictions
accuracies = with(predictions, c(rf=accuracy(predrf), gbm=accuracy(predgbm), lda=accuracy(predlda), stacked=accuracy(stackedpred)))
# Create predictions from stacked model
stackedpred = predict(stackedmod, newdata=testing$diagnosis)
source('~/R/TEST.R')
testing$diagnosis
stackedpred = predict(stackedmod, newdata=testing$diagnosis)
stackedmod
stackedpred = predict(stackedmod, newdata=testing)
stackedpred
source('~/R/TEST.R')
accuracies
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
names(getModelInfo())
getModelInfo()
getModelInfo("lasso")
?plot.enet
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
source('~/R/TEST.R')
lassomod
?plot.enet
plot.enet(lassomod)
str(lassomod)
?plot.enet
plot(lassomod, data=training)
plot.enet(lassomod, data=training)
plot.enet(lassomod, xvar="penalty", use.color=T)
plot.enet(lassomod$finalmodel, xvar="penalty", use.color=T)
plot.enet(lassomod$finalModel, xvar="penalty", use.color=T)
lassomod$finalModel
install.packages("forecast")
library(forecast)
?bats
source('~/R/TEST.R')
source('~/R/TEST.R')
?ts
?forecast
source('~/R/TEST.R')
tstest = ts(testing$visitsTumblr)
forecast = forecast(bats, tstest)
forecast = forecast(bats, newdata=tstest)
forecast
tstest
testing
nrow(tstest)
str(tstest)
length(tstest)
length(forecasr)
length(forecast)
length(tstrain)
training$visitsTumblr
tstrain
tstest
training
forecast = forecast(bats, newdata=testing)
forecast
testing
forecast = forecast(bats, newdata=testing, h=nrow(testing))
forecast
forecast = forecast(bats, newdata=testing, h=nrow(testing))$Forecast
forecast
forecast = forecast(bats, newdata=testing, h=nrow(testing))
forecast
ls(forecast)
names(forecast)
forcast$x
forecast$x
forecast$model
forecast$fitted
forecast
?ets
forecast = forecast(bats, newdata=testing)
forecast
forecast = forecast(bats, newdata=testing, h=nrow(testing))
forecast$"Point Forecast"
str(forecast)
forecast$mean
testign
testing
testing$VisitsTumblr
testing$visitsTumblr
names(forecast)
forecast$mean
forecast$upper
forecast$upper[,2]
testing$visitsTumblr < forecast$upper[,2]
forecast$lower
testing$visitsTumblr < forecast$upper[,2] & testing$visitsTumblr > forecast$lower[,2]
sum(testing$visitsTumblr < forecast$upper[,2] & testing$visitsTumblr > forecast$lower[,2])
sum(testing$visitsTumblr < forecast$upper[,2] & testing$visitsTumblr > forecast$lower[,2]) / length(testing$visitsTumblr)
library("e1071", lib.loc="~/R/win-library/3.1")
detach("package:e1071", unload=TRUE)
library("e1071", lib.loc="~/R/win-library/3.1")
source('~/R/TEST.R')
help(e1071)
help("e1071")
??e1071
?svm
source('~/R/TEST.R')
set.seed(325)
svm = svm(CompressiveStrength ~ ., data=training)
predictions = predict(svm, newdata=testing)
prediction
predictions
?rmse
class(predictions)
testing
testing$CompressiveStrength
testing$CompressiveStrength - predictions
mean((testing$CompressiveStrength - predictions) ^ 2)
sqrt(mean((testing$CompressiveStrength - predictions) ^ 2))
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
source('~/R/TEST.R')
accuracies
stacked[red]
stackedpred
testing$diagnosis
source('~/R/TEST.R')
source('~/R/TEST.R')
warnings()
testing$diagnosis
testing$diagnosis * 1
as.integer(testing$diagnosis)
source('~/R/TEST.R')
accuracy(predrf)
predrf
predrf == testing$diagnosis
sum(predrf == testing$diagnosis)
source('~/R/TEST.R')
accuracies
predrf
predrf == testing$diagnosis
sum(predrf == testing$diagnosis)
sum(predrf == testing$diagnosis) / length(testing$diagnosis)
source('~/R/TEST.R')
createDataPartition(training$diagnosis, p = 3/4)[[1]]
source('~/R/TEST.R')
source('~/R/TEST.R')
exists("rf")
exists("rf", inherits=F)
!exists("rf", inherits=F)
source('~/R/TEST.R')
warnings()
predrf
checking$diagnosis
accuracies
training$diagnosis
checking$diagnosis
testing$diagnosis
createDataPartition(adData$diagnosis, p = 3/4)[[1]]
createDataPartition(adData$diagnosis, p = 3/4)
createDataPartition(training$diagnosis, p = 3/4)[[1]]
createDataPartition(training$diagnosis, p = 3/4)
names(prediction   predrf = predict(rf, newdata=testing)
predgbm = predict(gbm, newdata=testing)
predlda = predict(lda, newdata=testing)
stackedpred = predict(stackedmod, newdata=testing))
predrf = predict(rf, newdata=testing)
predgbm = predict(gbm, newdata=testing)
predlda = predict(lda, newdata=testing)
stackedpred = predict(stackedmod, newdata=testing)
predictions = data.frame(predrf, predgbm, predlda, stackedpred)
accuracy = function(x, answers=testing$diagnosis) {
sum(x == answers) / length(answers)
}
accuracies = with(predictions, c(rf=accuracy(predrf), gbm=accuracy(predgbm), lda=accuracy(predlda),
stacked=accuracy(stackedpred)))
accuracies
private.yen1 = 2843
private.yen2 = 11492
cafetalk.yen = 120458
yen.dollar1 = (private.yen1 + cafetalk.yen) / 1185.04
private.yen1 / yen.dollar1
cafetalk / yen.dollar1
cafetalk.yen / yen.dollar1
private.yen2 = 11492
private.euro2 = 80
private.dollar2 = 109.62+104.17
18150*.9+(73800-18150)*.85 +(80000-73800)*.75
80000-11713
48500*.8687
42131.95/12
3510.996/2
75000-10462.5
64537.5/12
5378.125/2.125
64537.5/26
61000-8242.5
sal = c(65, 100, 65, 85, 70, 57, 80)
mean(sal)
sd(sal)
mean(sal) + c(sd(sal), -sd(sal))
sal
length(sal)
sal[7]
sal = sal[-7]
sal
mean(sal) + c(sd(sal), -sd(sal))
mean(sal)
med(sal)
median(sal)
sal = c(sal, 80)
median(sal)
18936-14106
4830/2
14106/2415
ctyen = 133924
peuro = 40
pyen = 2843+11492
159751/1493.04
jpyusdrate = 159751/1493.04
jpyusdrate
eurusdrate = 120/153.53
eurusdrate
pyen * jpyusdrate
pyen / jpyusdrate
pyen
pyen / jpyusdrate + peuro / eurusdrate
peuro / eurusdrate
ctyen / jpyusdrate
rm(pyen)
rm(peuro)
rm(ctyen)
peuro = 80
pyen = 11492
pyen / jpyusdrate
head(data[,-SOC])
source('~/Git/Kaggle_AfSIS/script.R')
head(data[,-SOC])
head(data[,-"SOC"])
head(data[,"SOC"])
head(data[,-"SOC"])
head(data$SOC)
head(data$-SOC)
head(data$(-SOC))
head(data[,names(data) !%in% outcomes])
head(data[,names(data) %in% outcomes])
data[,names(data) %in% outcomes]
names(data) %in% outcomes
names(data) !%in% outcomes
names(data) %in% !outcomes
!names(data) %in% outcomes
!(names(data) %in% outcomes)
head(data[,!(names(data) %in% outcomes)])
source('~/Git/Kaggle_AfSIS/feature_selection.R')
select.features(train, outcomes[1])
library(leaps)
?leaps
source('~/Git/Kaggle_AfSIS/feature_selection.R')
select.features(outcomes[1])
?regsubsets
select.features = function(outcome) {
model = formula(outcome ~ .)
regsubsets(model, y=data.matrix(data[,!(names(data) %in% outcomes)]), data[,outcome], method="Cp", really.big=T, data=data)
}
source('~/Git/Kaggle_AfSIS/feature_selection.R')
select.features(outcomes[1])
select.features = function(outcome) {
model = formula(outcome ~ .)
regsubsets(model, y=data.matrix(data[,!(names(data) %in% outcomes)]), data[,outcome], method="Cp", really.big=T, data=data)
}
model = formula(outcome ~ .)
model = formula(SOC ~ .)
regsubsets(x=data[,!(names(data) %in% outcomes)], y=data[,"SOC"], method="Cp", really.big=T)
head(data)
class(data)
sapply(data, class)
sapply(data, class) != "numeric"
which(sapply(data, class) != "numeric")
class(data$PIDN)
class(data$Depth)
head(data$Depth)
head(as.numeric(data$Depth))
head(as.numeric(data$Depth) - 1)
data$Depth = as.numeric(data$Depth) - 1
head(data$Depth)
head(data)
head(data[,1:5])
source('~/Git/Kaggle_AfSIS/script.R')
head(data[,1:5])
source('~/Git/Kaggle_AfSIS/feature_selection.R')
source('~/Git/Kaggle_AfSIS/script.R')
source('~/Git/Kaggle_AfSIS/feature_selection.R')
source('~/Git/Kaggle_AfSIS/script.R')
source('~/Git/Kaggle_AfSIS/feature_selection.R')
use.sample()
source('~/Git/Kaggle_AfSIS/feature_selection.R')
use.sample()
source('~/Git/Kaggle_AfSIS/feature_selection.R')
use.sample()
source('~/Git/Kaggle_AfSIS/feature_selection.R')
use.sample()
which(use.sample() == T)
class(use.sample())
source('~/Git/Kaggle_AfSIS/feature_selection.R')
rm(use.sample)
source('~/Git/Kaggle_AfSIS/feature_selection.R')
source('~/Git/Kaggle_AfSIS/feature_selection.R')
ignore.samples
ignore.samples()
names(ignore.samples())
source('~/Git/Kaggle_AfSIS/feature_selection.R')
ignore.samples()
?union
names(data)
ignore = ignore.samples()
ignore
union(ignore, "PIDN")
ignore = c("PIDN", ignore.samples())
ignore
head(data$Depth)
head(data$Depth, 30)
source('~/Git/Kaggle_AfSIS/script.R')
union(ignore)
union(!ignore)
union(ignore, NA)
union(ignore, NULL)
!union(ignore, NULL)
!(names(data) %in% ignore)
source('~/Git/Kaggle_AfSIS/script.R')
warnings()
head(data[,1:10], 10)
head(train[,1:10], 10)
train$Depth = as.numeric(train$Depth) - 1
head(train$Depth, 10)
rm(train)
source('~/Git/Kaggle_AfSIS/script.R')
head(train$Depth)
train$Depth = as.numeric(train$Depth) - 1
head(train$Depth)
